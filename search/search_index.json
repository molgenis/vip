{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Variant Interpretation Pipeline (VIP) \u00b6 VIP is a flexible human variant interpretation pipeline for rare disease using state-of-the-art pathogenicity prediction ( CAPICE ) and template-based interactive reporting to facilitate decision support. The VIP pipeline can be used starting from either your fastq , bam/cram or .g.vcf/vcf data, every entry point will result in a vcf file with your annotated, classified and filtered variants as well as a interactive HTML report with the same variants, prioritized by the CAPICE pathogenicity score and providing additional aids like a genome browser and a representation of the decisions leading to the VIP classification. VIP can be used for single patients, families or cohort data. Click here for a live example ] Above: report example Above: report example: genome browser","title":"Introduction"},{"location":"#variant-interpretation-pipeline-vip","text":"VIP is a flexible human variant interpretation pipeline for rare disease using state-of-the-art pathogenicity prediction ( CAPICE ) and template-based interactive reporting to facilitate decision support. The VIP pipeline can be used starting from either your fastq , bam/cram or .g.vcf/vcf data, every entry point will result in a vcf file with your annotated, classified and filtered variants as well as a interactive HTML report with the same variants, prioritized by the CAPICE pathogenicity score and providing additional aids like a genome browser and a representation of the decisions leading to the VIP classification. VIP can be used for single patients, families or cohort data. Click here for a live example ] Above: report example Above: report example: genome browser","title":"Variant Interpretation Pipeline (VIP)"},{"location":"about/acknowledgements/","text":"Acknowledgements \u00b6 Standing on the shoulders of giants. This project could not have possible without the existence of many other tools and resources. Among them we would like to thank the people behind the following projects: Ensembl Variant Effect Predictor (VEP) Nextflow AnnotSV Illumina ExpansionHunter Illumina Manta Illumina SpliceAI igv.js Clair3 Minimap2 GLnexus Samtools formats and tools Human Phenotype Ontology Consortium Clinical Genomic Database gnomAD ClinVar VKGL phyloP cuteSV","title":"Acknowledgements"},{"location":"about/acknowledgements/#acknowledgements","text":"Standing on the shoulders of giants. This project could not have possible without the existence of many other tools and resources. Among them we would like to thank the people behind the following projects: Ensembl Variant Effect Predictor (VEP) Nextflow AnnotSV Illumina ExpansionHunter Illumina Manta Illumina SpliceAI igv.js Clair3 Minimap2 GLnexus Samtools formats and tools Human Phenotype Ontology Consortium Clinical Genomic Database gnomAD ClinVar VKGL phyloP cuteSV","title":"Acknowledgements"},{"location":"about/license/","text":"License \u00b6 VIP is open source and available under the GNU Lesser General Public License v3.0 from https://github.com/molgenis/vip . See https://github.com/molgenis/vip/blob/main/LICENSE for details. Relationship to other licences \u00b6 VIP is an aggregate work of many works, each covered by their own licence(s). For the purposes of determining what you can do with specific works in VIP, this policy should be read together with the licence(s) of the relevant tools. For the avoidance of doubt, where any other licence grants rights, this policy does not modify or reduce those rights under those licences.","title":"License"},{"location":"about/license/#license","text":"VIP is open source and available under the GNU Lesser General Public License v3.0 from https://github.com/molgenis/vip . See https://github.com/molgenis/vip/blob/main/LICENSE for details.","title":"License"},{"location":"about/license/#relationship-to-other-licences","text":"VIP is an aggregate work of many works, each covered by their own licence(s). For the purposes of determining what you can do with specific works in VIP, this policy should be read together with the licence(s) of the relevant tools. For the avoidance of doubt, where any other licence grants rights, this policy does not modify or reduce those rights under those licences.","title":"Relationship to other licences"},{"location":"advanced/annotations/","text":"Annotations \u00b6 VEP \u00b6 VIP uses the Ensemble Effect Predictor to annotate all variants with their consequences. We use VEP with the refseq option for the transcripts, and with the flags for sift and polyphen annotations enabled. Plugins \u00b6 Below we describe the other sources which we annotate using the VEP plugin framework. CAPICE \u00b6 CAPICE is a computational method for predicting the pathogenicity of SNVs and InDels. It is a gradient boosting tree model trained using a variety of genomic annotations used by CADD score and trained on the clinical significance. CAPICE performs consistently across diverse independent synthetic, and real clinical data sets. It ourperforms the current best method in pathogenicity estimation for variants of different molecular consequences and allele frequency. We run the CAPICE application in the VIP pipeline and use a VEP plugin to annotate the VEP output with the scores from the CAPICE output file. VKGL \u00b6 The datashare workgroup of VKGL has set up a central database to enable mutual sharing of variant classifications through a partly automatic process. An additional goal is the public sharing of these data. The currently publicly available part of the database consists of DNA variant classifications established based on (former) diagnostic questions. We add the classifications from an export of the database and use a VEP plugin to annotate the VEP output with the classifications from the this file. SpliceAI \u00b6 SpliceAI is an open-source deep learning splicing prediction algorithm that has demonstrated in the past few years its high ability to predict splicing defects caused by DNA variations. We add the scores from the available precomputed scores of SpliceAI and use a copy of the available VEP plugin to annotate the VEP output with the classifications from the this file. AnnotSV \u00b6 AnnotSV is a program for annotating and ranking structural variations from genomes of several organisms. We run the AnnotSV application in the VIP pipeline and use a VEP plugin to annotate the VEP output with the scores from the AnnotSV output file. HPO \u00b6 A file based on the HPO phenotype_to_genes.txt is used to annotate VEP consequences with the inheritance modes associated with the gene of this consequence. Inheritance \u00b6 A file based on the CGD database is used to annotate VEP consequences with the inheritance modes associated with the gene of this consequence. Grantham \u00b6 The Grantham score attempts to predict the distance between two amino acids, in an evolutionary sense. A lower Grantham score reflects less evolutionary distance. A higher Grantham score reflects a greater evolutionary distance. We use a copy of the VEP plugin by Duarte Molha to annotate the VEP output with Grantham scores. GADO \u00b6 GADO can be used to prioritize genes based on the HPO terms of a patient.. We run the GADO commandline application in the VIP pipeline and use a VEP plugin to annotate the VEP output with the scores from the GADO output file.","title":"Annotations"},{"location":"advanced/annotations/#annotations","text":"","title":"Annotations"},{"location":"advanced/annotations/#vep","text":"VIP uses the Ensemble Effect Predictor to annotate all variants with their consequences. We use VEP with the refseq option for the transcripts, and with the flags for sift and polyphen annotations enabled.","title":"VEP"},{"location":"advanced/annotations/#plugins","text":"Below we describe the other sources which we annotate using the VEP plugin framework.","title":"Plugins"},{"location":"advanced/annotations/#capice","text":"CAPICE is a computational method for predicting the pathogenicity of SNVs and InDels. It is a gradient boosting tree model trained using a variety of genomic annotations used by CADD score and trained on the clinical significance. CAPICE performs consistently across diverse independent synthetic, and real clinical data sets. It ourperforms the current best method in pathogenicity estimation for variants of different molecular consequences and allele frequency. We run the CAPICE application in the VIP pipeline and use a VEP plugin to annotate the VEP output with the scores from the CAPICE output file.","title":"CAPICE"},{"location":"advanced/annotations/#vkgl","text":"The datashare workgroup of VKGL has set up a central database to enable mutual sharing of variant classifications through a partly automatic process. An additional goal is the public sharing of these data. The currently publicly available part of the database consists of DNA variant classifications established based on (former) diagnostic questions. We add the classifications from an export of the database and use a VEP plugin to annotate the VEP output with the classifications from the this file.","title":"VKGL"},{"location":"advanced/annotations/#spliceai","text":"SpliceAI is an open-source deep learning splicing prediction algorithm that has demonstrated in the past few years its high ability to predict splicing defects caused by DNA variations. We add the scores from the available precomputed scores of SpliceAI and use a copy of the available VEP plugin to annotate the VEP output with the classifications from the this file.","title":"SpliceAI"},{"location":"advanced/annotations/#annotsv","text":"AnnotSV is a program for annotating and ranking structural variations from genomes of several organisms. We run the AnnotSV application in the VIP pipeline and use a VEP plugin to annotate the VEP output with the scores from the AnnotSV output file.","title":"AnnotSV"},{"location":"advanced/annotations/#hpo","text":"A file based on the HPO phenotype_to_genes.txt is used to annotate VEP consequences with the inheritance modes associated with the gene of this consequence.","title":"HPO"},{"location":"advanced/annotations/#inheritance","text":"A file based on the CGD database is used to annotate VEP consequences with the inheritance modes associated with the gene of this consequence.","title":"Inheritance"},{"location":"advanced/annotations/#grantham","text":"The Grantham score attempts to predict the distance between two amino acids, in an evolutionary sense. A lower Grantham score reflects less evolutionary distance. A higher Grantham score reflects a greater evolutionary distance. We use a copy of the VEP plugin by Duarte Molha to annotate the VEP output with Grantham scores.","title":"Grantham"},{"location":"advanced/annotations/#gado","text":"GADO can be used to prioritize genes based on the HPO terms of a patient.. We run the GADO commandline application in the VIP pipeline and use a VEP plugin to annotate the VEP output with the scores from the GADO output file.","title":"GADO"},{"location":"advanced/classification_trees/","text":"Classification trees \u00b6 In order to end up with a small list of candidate variant records for interpretation VIP performs variant filtration by: Classify all variant-consequences based on variant annotations Remove variant-consequences based on their classes Annotate remaining variant records using inheritance matcher Classify all variant-consequences based on variant annotations in the context of samples Remove variant-consequences based on their classes. Remove variants that had all their variant-consequences removed The following sections describe the default variant filtration strategies and how to customize classification and filtration. Default \u00b6 VIP contains default filtration strategies for variant-consequences (GRCh37 and GRCh38) as well as variant-consequences in the context of samples. Variant-consequences \u00b6 The default decision tree to classify variant-consequences works as follows: Each variant-consequence is classified as Benign , Likely Benign , VUS , Likely Pathogenic , Pathogenic or Remove Variant-consequences classified as Benign , Likely Benign and Remove are removed Above: default GRCh38 variant classification tree Variant-consequences (samples) \u00b6 The default decision tree to classify variant-consequences in the context of samples works as follows: Each variant-consequence-sample is classified as OK , LQ (low quality), HR (homozygous reference) or MV (mendelian violation) Variant-consequences classified as LQ or HR for all samples are removed Above: default variant sample classification tree Customization \u00b6 The default variant filtration strategy can be customized using the following parameters (see here ): vcf.classify.GRCh37.decision_tree vcf.classify.GRCh38.decision_tree vcf.filter.classes vcf.classify_samples.GRCh37.decision_tree vcf.classify_samples.GRCh38.decision_tree vcf.filter_samples.classes The following repositories might be of interest when creating a new decision tree: vip vip-decision-tree You are free to use your own set of classes in your decision tree. Keep in mind to update the filter classes parameters accordingly.","title":"Classification trees"},{"location":"advanced/classification_trees/#classification-trees","text":"In order to end up with a small list of candidate variant records for interpretation VIP performs variant filtration by: Classify all variant-consequences based on variant annotations Remove variant-consequences based on their classes Annotate remaining variant records using inheritance matcher Classify all variant-consequences based on variant annotations in the context of samples Remove variant-consequences based on their classes. Remove variants that had all their variant-consequences removed The following sections describe the default variant filtration strategies and how to customize classification and filtration.","title":"Classification trees"},{"location":"advanced/classification_trees/#default","text":"VIP contains default filtration strategies for variant-consequences (GRCh37 and GRCh38) as well as variant-consequences in the context of samples.","title":"Default"},{"location":"advanced/classification_trees/#variant-consequences","text":"The default decision tree to classify variant-consequences works as follows: Each variant-consequence is classified as Benign , Likely Benign , VUS , Likely Pathogenic , Pathogenic or Remove Variant-consequences classified as Benign , Likely Benign and Remove are removed Above: default GRCh38 variant classification tree","title":"Variant-consequences"},{"location":"advanced/classification_trees/#variant-consequences-samples","text":"The default decision tree to classify variant-consequences in the context of samples works as follows: Each variant-consequence-sample is classified as OK , LQ (low quality), HR (homozygous reference) or MV (mendelian violation) Variant-consequences classified as LQ or HR for all samples are removed Above: default variant sample classification tree","title":"Variant-consequences (samples)"},{"location":"advanced/classification_trees/#customization","text":"The default variant filtration strategy can be customized using the following parameters (see here ): vcf.classify.GRCh37.decision_tree vcf.classify.GRCh38.decision_tree vcf.filter.classes vcf.classify_samples.GRCh37.decision_tree vcf.classify_samples.GRCh38.decision_tree vcf.filter_samples.classes The following repositories might be of interest when creating a new decision tree: vip vip-decision-tree You are free to use your own set of classes in your decision tree. Keep in mind to update the filter classes parameters accordingly.","title":"Customization"},{"location":"advanced/report_templates/","text":"Report templates \u00b6 VIP outputs a standalone HTML report that can be viewed in any modern browser. The report is based on the input sample sheet information and the output variant vcf data. Default \u00b6 As a default VIP uses a report template that is suitable for most analysis: Above: default report template Customization \u00b6 Using the vcf.report.template parameter (see here ) it is possible to specify a different report template to create reports tailered to your needs. The following repositories might be of interest when creating a new report template: vip-report-api vip-report-template vip-report-vcf vite-plugin-inline The vip-report tool creates reports based on a report template as described in the following repositories: vip-report vip-utils","title":"Report templates"},{"location":"advanced/report_templates/#report-templates","text":"VIP outputs a standalone HTML report that can be viewed in any modern browser. The report is based on the input sample sheet information and the output variant vcf data.","title":"Report templates"},{"location":"advanced/report_templates/#default","text":"As a default VIP uses a report template that is suitable for most analysis: Above: default report template","title":"Default"},{"location":"advanced/report_templates/#customization","text":"Using the vcf.report.template parameter (see here ) it is possible to specify a different report template to create reports tailered to your needs. The following repositories might be of interest when creating a new report template: vip-report-api vip-report-template vip-report-vcf vite-plugin-inline The vip-report tool creates reports based on a report template as described in the following repositories: vip-report vip-utils","title":"Customization"},{"location":"examples/multi-project/","text":"Multi-project \u00b6 VIP can be used to analyse different projects in one run, producing output files per project. To achieve this you just need to specify different projects in one samplesheet. family_id individual_id paternal_id maternal_id sex affected proband sequencing_platform fastq fastq_r1 fastq_r2 vip0 fam0 individual0 individual1 male true true nanopore path/to/vip0.fastq.gz vip0 fam0 individual1 female false false nanopore path/to/vip1.fastq.gz vip1 fam1 individual2 individual3 individual4 male false false paacbio_hifi path/to/vip2.fastq.gz vip1 fam1 individual3 male false false pacbio_hifi path/to/vip3.fastq.gz vip1 fam1 individual4 female false true pacbio_hifi path/to/vip4.fastq.gz vip2 fam2 individual5 male true true illumina /vip5_1.fastq.gz /vip5_2.fastq.gz Run the pipeline \u00b6 cd vip vip --workflow fastq --input path/to/samplesheet.tsv --output path/to/output/folder For a working example on how to generate output for multiple projects see here .","title":"Multi-project"},{"location":"examples/multi-project/#multi-project","text":"VIP can be used to analyse different projects in one run, producing output files per project. To achieve this you just need to specify different projects in one samplesheet. family_id individual_id paternal_id maternal_id sex affected proband sequencing_platform fastq fastq_r1 fastq_r2 vip0 fam0 individual0 individual1 male true true nanopore path/to/vip0.fastq.gz vip0 fam0 individual1 female false false nanopore path/to/vip1.fastq.gz vip1 fam1 individual2 individual3 individual4 male false false paacbio_hifi path/to/vip2.fastq.gz vip1 fam1 individual3 male false false pacbio_hifi path/to/vip3.fastq.gz vip1 fam1 individual4 female false true pacbio_hifi path/to/vip4.fastq.gz vip2 fam2 individual5 male true true illumina /vip5_1.fastq.gz /vip5_2.fastq.gz","title":"Multi-project"},{"location":"examples/multi-project/#run-the-pipeline","text":"cd vip vip --workflow fastq --input path/to/samplesheet.tsv --output path/to/output/folder For a working example on how to generate output for multiple projects see here .","title":"Run the pipeline"},{"location":"examples/nanopore/","text":"Nanopore \u00b6 To run vip with nanopore data, just specify nanopore as the sequencing_platform in your sample sheet. The other options for this field are \"illumina\" and \"pacbio_hifi\" and can be used in a similar manner. Samplesheet \u00b6 See an example for the samplesheet below, the example show the samplesheet for a run starting from the cram, but the 'sequencing_platform' can also be used to achieve the same for a run with the fastq workflow. individual_id sequencing_platform cram your_sample_id nanopore path/to/your/nanopore.cram Run the pipeline \u00b6 cd vip vip --workflow cram --input path/to/samplesheet.tsv --output path/to/output/folder For an example on how to generate output for FASTQ files using the Oxford Nanopore platform see here .","title":"Nanopore"},{"location":"examples/nanopore/#nanopore","text":"To run vip with nanopore data, just specify nanopore as the sequencing_platform in your sample sheet. The other options for this field are \"illumina\" and \"pacbio_hifi\" and can be used in a similar manner.","title":"Nanopore"},{"location":"examples/nanopore/#samplesheet","text":"See an example for the samplesheet below, the example show the samplesheet for a run starting from the cram, but the 'sequencing_platform' can also be used to achieve the same for a run with the fastq workflow. individual_id sequencing_platform cram your_sample_id nanopore path/to/your/nanopore.cram","title":"Samplesheet"},{"location":"examples/nanopore/#run-the-pipeline","text":"cd vip vip --workflow cram --input path/to/samplesheet.tsv --output path/to/output/folder For an example on how to generate output for FASTQ files using the Oxford Nanopore platform see here .","title":"Run the pipeline"},{"location":"examples/reanalysis/","text":"Reanalysis \u00b6 The VCF workflow can be used to reanalyse data from previous runs with the pipeline. It is possible to start from the normalize, annotate, classify, filter, inheritance, classify_samples, filter_samples steps, this can for example be usefull if you update one of your decision trees, or if you which to re-run the inheritance matching with a different set of low-penetrance genes. For reanalysis the basics of running VIp remain the same, however the correct intermediate file should be provided as input in the sample sheet. Several intermediate results are available in the \"intermediates\" subfolder of your output folder. Furthermore the step form which you whish to start should be added in the configuration parameter \"vcf.start\" For an example on how to reanalyze VIP data using a different classification tree see here .","title":"Reanalysis"},{"location":"examples/reanalysis/#reanalysis","text":"The VCF workflow can be used to reanalyse data from previous runs with the pipeline. It is possible to start from the normalize, annotate, classify, filter, inheritance, classify_samples, filter_samples steps, this can for example be usefull if you update one of your decision trees, or if you which to re-run the inheritance matching with a different set of low-penetrance genes. For reanalysis the basics of running VIp remain the same, however the correct intermediate file should be provided as input in the sample sheet. Several intermediate results are available in the \"intermediates\" subfolder of your output folder. Furthermore the step form which you whish to start should be added in the configuration parameter \"vcf.start\" For an example on how to reanalyze VIP data using a different classification tree see here .","title":"Reanalysis"},{"location":"get_started/installation/","text":"Installation \u00b6 git clone https://github.com/molgenis/vip bash vip/install.sh By default, the installation script downloads resources for both GRCh37 and GRCh38 assemblies. Options \u00b6 Use --assembly to limit the downloaded resources to a specific assembly: bash vip/install.sh --assembly GRCh37 bash vip/install.sh --assembly GRCh38","title":"Installation"},{"location":"get_started/installation/#installation","text":"git clone https://github.com/molgenis/vip bash vip/install.sh By default, the installation script downloads resources for both GRCh37 and GRCh38 assemblies.","title":"Installation"},{"location":"get_started/installation/#options","text":"Use --assembly to limit the downloaded resources to a specific assembly: bash vip/install.sh --assembly GRCh37 bash vip/install.sh --assembly GRCh38","title":"Options"},{"location":"get_started/requirements/","text":"Requirements \u00b6 Before installing VIP please check whether your system meets the following requirements: POSIX compatible system (e.g. Linux, macOS, Windows Subsystem for Linux ) with x86_64 architecture (AArch64 not supported) Bash \u2265 3.2 Java \u2265 11 Apptainer (setuid installation) 8GB RAM 1 200-400GB disk space 2 1) The memory requirements differ per workflow and depend, on the size of your input data, the scheduler that you use, the amount of parallelization. For example, executing VIP using a job scheduler will reduce the memory requirements on the system submitting the jobs to 1-2GB. 2) The disk space requirements are determined by the installation options, for more details see here . Installing VIP for only GRCh37 or only for GRCh38 will cut down requirements roughly by 50%. Optional \u00b6 VIP auto-detects whether Slurm is available on the system and, if available, will schedule its jobs with Slurm. Otherwise, the jobs will be submitted on the local system.","title":"Requirements"},{"location":"get_started/requirements/#requirements","text":"Before installing VIP please check whether your system meets the following requirements: POSIX compatible system (e.g. Linux, macOS, Windows Subsystem for Linux ) with x86_64 architecture (AArch64 not supported) Bash \u2265 3.2 Java \u2265 11 Apptainer (setuid installation) 8GB RAM 1 200-400GB disk space 2 1) The memory requirements differ per workflow and depend, on the size of your input data, the scheduler that you use, the amount of parallelization. For example, executing VIP using a job scheduler will reduce the memory requirements on the system submitting the jobs to 1-2GB. 2) The disk space requirements are determined by the installation options, for more details see here . Installing VIP for only GRCh37 or only for GRCh38 will cut down requirements roughly by 50%.","title":"Requirements"},{"location":"get_started/requirements/#optional","text":"VIP auto-detects whether Slurm is available on the system and, if available, will schedule its jobs with Slurm. Otherwise, the jobs will be submitted on the local system.","title":"Optional"},{"location":"get_started/start_running/","text":"Start running \u00b6 After installation, it is time for a quick test to verify that VIP works using some test data. Input \u00b6 To run VIP you need to provide at least workflow , input and output arguments (described in detail here ). The following example processes a collection of .vcf files. cd vip vip --workflow vcf --input test/resources/multiproject.tsv --output output_multiproject Output \u00b6 Executing the above command displays progress until the pipeline completes. N E X T F L O W ~ version 22.10.6 Launching `vip_vcf.nf` [disturbed_khorana] DSL2 - revision: 8f8c80809c executor > local (27) [- ] process > samtools_index - [71/4bb8b5] process > vcf:convert (2) [100%] 5 of 5 \u2714 [c7/1f8dc7] process > vcf:index (1) [100%] 1 of 1 \u2714 [ad/51639f] process > vcf:stats (1) [100%] 2 of 2 \u2714 [54/a6c17d] process > vcf:merge_vcf (1) [100%] 1 of 1 \u2714 [a5/790ba1] process > vcf:merge_gvcf (1) [100%] 1 of 1 \u2714 [- ] process > vcf:split - [64/dafd8f] process > vcf:normalize (2) [100%] 2 of 2 \u2714 [c4/ed6e06] process > vcf:annotate (1) [100%] 2 of 2 \u2714 [43/c63075] process > vcf:classify (2) [100%] 2 of 2 \u2714 [66/3adcef] process > vcf:filter (2) [100%] 2 of 2 \u2714 [d1/1d89ee] process > vcf:inheritance (1) [100%] 2 of 2 \u2714 [d7/d717a0] process > vcf:classify_samples (1) [100%] 2 of 2 \u2714 [45/0564f9] process > vcf:filter_samples (1) [100%] 2 of 2 \u2714 [- ] process > vcf:concat - [- ] process > vcf:slice - [ad/fc2b6c] process > vcf:report (2) [100%] 3 of 3 \u2714 Duration : 1m 00s CPU hours : 0.2 Succeeded : 27 Results \u00b6 ls -1 output_multiproject/ The output folder contains one report for each project described in test/resources/multiproject.tsv . intermediates nxf_report.html nxf_timeline.html vip0.html vip0.vcf.gz vip0.vcf.gz.csi vip1.html vip1.vcf.gz vip1.vcf.gz.csi vip2.html vip2.vcf.gz vip2.vcf.gz.csi The files vip0.html , vip1.html and vip2.html can be opened in your browser and display an interactive report based on the corresponding .vcf.gz output files. The outputs are described in more detail here .","title":"Start running"},{"location":"get_started/start_running/#start-running","text":"After installation, it is time for a quick test to verify that VIP works using some test data.","title":"Start running"},{"location":"get_started/start_running/#input","text":"To run VIP you need to provide at least workflow , input and output arguments (described in detail here ). The following example processes a collection of .vcf files. cd vip vip --workflow vcf --input test/resources/multiproject.tsv --output output_multiproject","title":"Input"},{"location":"get_started/start_running/#output","text":"Executing the above command displays progress until the pipeline completes. N E X T F L O W ~ version 22.10.6 Launching `vip_vcf.nf` [disturbed_khorana] DSL2 - revision: 8f8c80809c executor > local (27) [- ] process > samtools_index - [71/4bb8b5] process > vcf:convert (2) [100%] 5 of 5 \u2714 [c7/1f8dc7] process > vcf:index (1) [100%] 1 of 1 \u2714 [ad/51639f] process > vcf:stats (1) [100%] 2 of 2 \u2714 [54/a6c17d] process > vcf:merge_vcf (1) [100%] 1 of 1 \u2714 [a5/790ba1] process > vcf:merge_gvcf (1) [100%] 1 of 1 \u2714 [- ] process > vcf:split - [64/dafd8f] process > vcf:normalize (2) [100%] 2 of 2 \u2714 [c4/ed6e06] process > vcf:annotate (1) [100%] 2 of 2 \u2714 [43/c63075] process > vcf:classify (2) [100%] 2 of 2 \u2714 [66/3adcef] process > vcf:filter (2) [100%] 2 of 2 \u2714 [d1/1d89ee] process > vcf:inheritance (1) [100%] 2 of 2 \u2714 [d7/d717a0] process > vcf:classify_samples (1) [100%] 2 of 2 \u2714 [45/0564f9] process > vcf:filter_samples (1) [100%] 2 of 2 \u2714 [- ] process > vcf:concat - [- ] process > vcf:slice - [ad/fc2b6c] process > vcf:report (2) [100%] 3 of 3 \u2714 Duration : 1m 00s CPU hours : 0.2 Succeeded : 27","title":"Output"},{"location":"get_started/start_running/#results","text":"ls -1 output_multiproject/ The output folder contains one report for each project described in test/resources/multiproject.tsv . intermediates nxf_report.html nxf_timeline.html vip0.html vip0.vcf.gz vip0.vcf.gz.csi vip1.html vip1.vcf.gz vip1.vcf.gz.csi vip2.html vip2.vcf.gz vip2.vcf.gz.csi The files vip0.html , vip1.html and vip2.html can be opened in your browser and display an interactive report based on the corresponding .vcf.gz output files. The outputs are described in more detail here .","title":"Results"},{"location":"help/frequently_asked_questions/","text":"Frequently asked questions \u00b6 Why doesn't my report contain any variants? \u00b6 VIP filters your input variants using classification trees for variant-effect and variant-sample combinations. Usually if your report doesn't contain any records this implies that they were filtered out based on these trees. Inspect the _classifications.vcf.gz files in the intermediates output folder to determine why a variant record was removed. The default VIP classification tree and class filter removes variants on the 'non-standard' contigs. For GRCh37 this implies [1-22,X,Y,MT]. The hg19 GRCh37 reference sequence uses different contigs identifiers which will result in filtering out of all records. In this case you should provide your own classification tree with the correct contig identifiers. Why does VIP fail with an Unexpected Error [InvocationTargetException] ? \u00b6 This issue can mean a number of things, check the .nxf.log for more details. One of the causes is a mismatch between the reference genome that was used to call the variants in your .vcf file and the reference genome used by VIP. For example: Your variants are called with a reference genome that differs from the default VIP reference genome Your variants are called with GRCh37 and you use the GRCh38 assembly or vice-versa Why does VIP fail with a file not found error but my file exists? \u00b6 You might need to update APPTAINER_BIND , for more details see here . To understand the cause of this issue take a look at the Apptainer documentation . Why does VIP fail with an exit code 137? \u00b6 A process has run out of memory. See the config documentation on how to update resource assignments for some or all processes.","title":"Frequently asked questions"},{"location":"help/frequently_asked_questions/#frequently-asked-questions","text":"","title":"Frequently asked questions"},{"location":"help/frequently_asked_questions/#why-doesnt-my-report-contain-any-variants","text":"VIP filters your input variants using classification trees for variant-effect and variant-sample combinations. Usually if your report doesn't contain any records this implies that they were filtered out based on these trees. Inspect the _classifications.vcf.gz files in the intermediates output folder to determine why a variant record was removed. The default VIP classification tree and class filter removes variants on the 'non-standard' contigs. For GRCh37 this implies [1-22,X,Y,MT]. The hg19 GRCh37 reference sequence uses different contigs identifiers which will result in filtering out of all records. In this case you should provide your own classification tree with the correct contig identifiers.","title":"Why doesn't my report contain any variants?"},{"location":"help/frequently_asked_questions/#why-does-vip-fail-with-an-unexpected-error-invocationtargetexception","text":"This issue can mean a number of things, check the .nxf.log for more details. One of the causes is a mismatch between the reference genome that was used to call the variants in your .vcf file and the reference genome used by VIP. For example: Your variants are called with a reference genome that differs from the default VIP reference genome Your variants are called with GRCh37 and you use the GRCh38 assembly or vice-versa","title":"Why does VIP fail with an Unexpected Error [InvocationTargetException]?"},{"location":"help/frequently_asked_questions/#why-does-vip-fail-with-a-file-not-found-error-but-my-file-exists","text":"You might need to update APPTAINER_BIND , for more details see here . To understand the cause of this issue take a look at the Apptainer documentation .","title":"Why does VIP fail with a file not found error but my file exists?"},{"location":"help/frequently_asked_questions/#why-does-vip-fail-with-an-exit-code-137","text":"A process has run out of memory. See the config documentation on how to update resource assignments for some or all processes.","title":"Why does VIP fail with an exit code 137?"},{"location":"help/issues/","text":"Issues \u00b6 Please use this link to report issues or ask questions. We do not have an e-mail address, forum or community chat at the moment. Known issues might be located in one of our VIP repositories: vip vip-decision-tree vip-inheritance vip-inheritance-matcher vip-report vip-report-api vip-report-template vip-report-vcf vip-utils capice vite-plugin-inline","title":"Issues"},{"location":"help/issues/#issues","text":"Please use this link to report issues or ask questions. We do not have an e-mail address, forum or community chat at the moment. Known issues might be located in one of our VIP repositories: vip vip-decision-tree vip-inheritance vip-inheritance-matcher vip-report vip-report-api vip-report-template vip-report-vcf vip-utils capice vite-plugin-inline","title":"Issues"},{"location":"home/key_features/","text":"Key features \u00b6 VIP is an easy to install, easy to use, portable and flexible pipeline implemented using Nextflow . Features include: Workflows for a broad range of input file types: bam , cram , fastq , g.vcf , vcf Produces stand-alone variant interpretation HTML report with integrated genome browser Long-read sequencing support (Oxford Nanopore, PacBio HiFi) Short-read sequencing support (Illumina, both single and paired-end reads) Supports GRCh37 and GRCh38 Short variant detection Limitation: VIP currently does not support short variant detection on Mitochondrial DNA Structural variant detection Consequence-agnostic Rich set of variant annotations Pathogenic variant prioritization (CAPICE) Phenotype support (HPO) Inheritance matching (VIP inheritance matcher) Variant classification and filtration using customizable decision trees Variant reporting using customizable report templates Quick reanalysis","title":"Key features"},{"location":"home/key_features/#key-features","text":"VIP is an easy to install, easy to use, portable and flexible pipeline implemented using Nextflow . Features include: Workflows for a broad range of input file types: bam , cram , fastq , g.vcf , vcf Produces stand-alone variant interpretation HTML report with integrated genome browser Long-read sequencing support (Oxford Nanopore, PacBio HiFi) Short-read sequencing support (Illumina, both single and paired-end reads) Supports GRCh37 and GRCh38 Short variant detection Limitation: VIP currently does not support short variant detection on Mitochondrial DNA Structural variant detection Consequence-agnostic Rich set of variant annotations Pathogenic variant prioritization (CAPICE) Phenotype support (HPO) Inheritance matching (VIP inheritance matcher) Variant classification and filtration using customizable decision trees Variant reporting using customizable report templates Quick reanalysis","title":"Key features"},{"location":"usage/command-line-options/","text":"Command-line options \u00b6 The vip command takes input vcf/cram/fastq data and produces a filtered annotated .vcf.gz containing candidate variants of interest. In addition to the .vcf.gz an interactive .html report is produced that can be displayed in any modern web browser. vip --help prints the available command-line options: usage: vip -w <arg> -i <arg> -o <arg> -w, --workflow <arg> workflow to execute. allowed values: cram, fastq, vcf -i, --input <arg> path to sample sheet .tsv -o, --output <arg> output folder -c, --config <arg> path to additional nextflow .cfg (optional) -p, --profile <arg> nextflow configuration profile (optional) -r, --resume resume execution using cached results (default: false) -h, --help print this message and exit Required \u00b6 workflow as described here input as described here output as described here Optional \u00b6 config as described here profile the configuration profile to use. allowed values are local , slurm plus any profiles added in --config resume useful to continue executions that was stopped by an error using cached results Defaults \u00b6 By default vip : Assumes an Illumina sequencing platform was used to generate the input data Assumes whole-genome sequencing (WGS) method was used to generate the input data Uses a GRCh38 reference genome ( GCA_000001405.15 / GCF_000001405.26 ) Provides classification trees for default variant filtration. For details, see here Creates reports using a default report template. For details, see here","title":"Command-line options"},{"location":"usage/command-line-options/#command-line-options","text":"The vip command takes input vcf/cram/fastq data and produces a filtered annotated .vcf.gz containing candidate variants of interest. In addition to the .vcf.gz an interactive .html report is produced that can be displayed in any modern web browser. vip --help prints the available command-line options: usage: vip -w <arg> -i <arg> -o <arg> -w, --workflow <arg> workflow to execute. allowed values: cram, fastq, vcf -i, --input <arg> path to sample sheet .tsv -o, --output <arg> output folder -c, --config <arg> path to additional nextflow .cfg (optional) -p, --profile <arg> nextflow configuration profile (optional) -r, --resume resume execution using cached results (default: false) -h, --help print this message and exit","title":"Command-line options"},{"location":"usage/command-line-options/#required","text":"workflow as described here input as described here output as described here","title":"Required"},{"location":"usage/command-line-options/#optional","text":"config as described here profile the configuration profile to use. allowed values are local , slurm plus any profiles added in --config resume useful to continue executions that was stopped by an error using cached results","title":"Optional"},{"location":"usage/command-line-options/#defaults","text":"By default vip : Assumes an Illumina sequencing platform was used to generate the input data Assumes whole-genome sequencing (WGS) method was used to generate the input data Uses a GRCh38 reference genome ( GCA_000001405.15 / GCF_000001405.26 ) Provides classification trees for default variant filtration. For details, see here Creates reports using a default report template. For details, see here","title":"Defaults"},{"location":"usage/config/","text":"Config \u00b6 The VIP configuration is stored in Nextflow configuration files. An additional configuration file can be supplied on the command-line to overwrite default parameter values, add/update profiles, configure processes and update environment variables. Parameters \u00b6 key default description GRCh37.reference.fasta installed human_g1k_v37 GRCh37.reference.fastaFai installed GRCh37.reference.fastaGzi installed GRCh38.reference.fasta installed GCA_000001405.15_GRCh38_no_alt_analysis_set GRCh38.reference.fastaFai installed GRCh38.reference.fastaGzi installed Warning: Please take note of the fact that for a different reference fasta.gz the unzipped referenfasta file is also required. Both the zipped and unzipped fasta should have an index. FASTQ \u00b6 key default description GRCh37.reference.fastaMmi installed for details, see here GRCh38.reference.fastaMmi installed for details, see here minimap2.soft_clipping true In SAM output, use soft clipping for supplementary alignments (required when STR calling with Straglr) CRAM \u00b6 key default description cram.call_snv true enable/disable the detection of short variants cram.call_str true enable/disable the detection of short tandem repeats cram.call_sv true enable/disable the detection of structural variants snv.clair3.illumina.model_name ilmn for details, see here snv.clair3.nanopore.model_name r941_prom_sup_g5014 for details, see here snv.clair3.pacbio_hifi.model_name hifi for details, see here str.expansionhunter.aligner dag-aligner for details, see here . allowed values: [dag-aligner, path-aligner] str.expansionhunter.analysis_mode streaming for details, see here . allowed values: [seeking , streaming] str.expansionhunter.log_level warn for details, see here . allowed values: [trace, debug, info, warn, or error] str.expansionhunter.region_extension_length 1000 for details, see here str.expansionhunter.GRCh37.variant_catalog installed for details, see here str.expansionhunter.GRCh38.variant_catalog installed for details, see here str.straglr.min_support 2 minimum number of support reads for an expansion to be captured in genome-scan, see here str.straglr.min_cluster_size 2 minimum number of reads required to constitute a cluster (allele) in GMM clustering, see here str.straglr.GRCh38.loci installed from here VCF \u00b6 key default description vcf.start allowed values: [normalize, annotate, classify, filter, inheritance, classify_samples, filter_samples]. for reanalysis this defines from which step to start the workflow vcf.annotate.annotsv_cache_dir installed vcf.annotate.ensembl_gene_mapping installed vcf.annotate.vep_buffer_size 1000 for details, see here vcf.annotate.vep_cache_dir installed vcf.annotate.vep_plugin_dir installed vcf.annotate.vep_plugin_hpo installed vcf.annotate.vep_plugin_inheritance installed vcf.annotate.vep_plugin_vkgl_mode 1 allowed values: [0=full VKGL, 1=public VKGL]. update vcf.annotate.GRCh38.vep_plugin_vkgl accordingly vcf.annotate.GRCh37.capice_model installed vcf.annotate.GRCh37.vep_custom_gnomad installed vcf.annotate.GRCh37.vep_custom_clinvar installed vcf.annotate.GRCh37.vep_custom_phylop installed vcf.annotate.GRCh37.vep_plugin_spliceai_indel installed vcf.annotate.GRCh37.vep_plugin_spliceai_snv installed vcf.annotate.GRCh37.vep_plugin_utrannotator installed vcf.annotate.GRCh37.vep_plugin_vkgl installed vcf.annotate.GRCh38.capice_model installed vcf.annotate.GRCh38.vep_custom_gnomad installed vcf.annotate.GRCh38.vep_custom_clinvar installed vcf.annotate.GRCh38.vep_custom_phylop installed vcf.annotate.GRCh38.vep_plugin_spliceai_indel installed vcf.annotate.GRCh38.vep_plugin_spliceai_snv installed vcf.annotate.GRCh38.vep_plugin_utrannotator installed vcf.annotate.GRCh38.vep_plugin_vkgl installed update vcf.annotate.vep_plugin_vkgl_mode accordingly vcf.classify.annotate_labels 0 allowed values: [0=false, 1=true]. annotate variant-consequences with classification tree labels vcf.classify.annotate_path 1 allowed values: [0=false, 1=true]. annotate variant-consequences with classification tree path vcf.classify.GRCh37.decision_tree installed for details, see here vcf.classify.GRCh38.decision_tree installed for details, see here vcf.classify_samples.annotate_labels 0 allowed values: [0=false, 1=true]. annotate variant-consequences per sample with classification tree labels vcf.classify_samples.annotate_path 1 allowed values: [0=false, 1=true]. annotate variant-consequences per sample with classification tree path vcf.classify_samples.GRCh37.decision_tree installed for details, see here vcf.classify_samples.GRCh38.decision_tree installed for details, see here vcf.filter.classes VUS,LP,P for details, see here vcf.filter.consequences true allowed values: [true, false]. true: filter individual consequences, false: keep all consequences for a variant if one consequence filter passes. vcf.filter_samples.classes MV,OK for details, see here vcf.report.gado_genes installed vcf.report.gado_hpo installed vcf.report.gado_predict_info installed vcf.report.gado_predict_matrix installed vcf.report.include_crams true allowed values: [true, false]. true: include cram files in the report for showing alignments in the genome browser, false: do not include the crams in the report, no aligments are shown in the genome browser. This will result in a smaller report size. vcf.report.max_records vcf.report.max_samples vcf.report.template for details, see here vcf.report.GRCh37.genes installed vcf.report.GRCh38.genes installed Profiles \u00b6 VIP pre-defines two profiles. The default profile is Slurm with fallback to local in case Slurm cannot be discovered. key description local for details, see here slurm for details, see here Additional profiles (for details, see here ) can be added to your configuration file and used on the command-line, for example to run VIP on the Amazon, Azure or Google Cloud. Process \u00b6 By default, each process gets assigned 4 cpus , 8GB of memory and a max runtime of 4 hours . Depending on your system specifications and your analysis you might need to use updated values. For information on how to update process configuration see the Nextflow documentation . The following sections list all processes and their non-default configuration. FASTQ \u00b6 process configuration concat_fastq default concat_fastq_paired_end default minimap2_align cpus=8 memory='16GB' time='23h' minimap2_align_paired_end cpus=8 memory='16GB' time='23h' minimap2_index cpus=8 memory='16GB' time='23h' CRAM \u00b6 process configuration samtools_addreplacerg default clair3_call cpus=4 memory='8GB' time='5h' clair3_call_publish default manta_call cpus=4 memory='8GB' time='5h' manta_call_publish default samtools_index default cutesv_call cpus=4 memory='8GB' time='5h' VCF \u00b6 process configuration annotate cpus=4 memory='8GB' time='4h' annotate_publish default classify memory = '2GB' classify_publish default classify_samples memory = '2GB' classify_samples_publish default concat default convert default filter default filter_samples default index memory='100MB' time='30m' inheritance memory = '2GB' merge_gvcf memory='2GB' time='30m' merge_vcf default normalize default report memory = '4GB' slice default split memory='100MB' time='30m' stats default Environment \u00b6 See https://github.com/molgenis/vip/tree/main/config for an overview of available environment variables. Notably this allows to use different Apptainer containers for the tools that VIP relies on.","title":"Config"},{"location":"usage/config/#config","text":"The VIP configuration is stored in Nextflow configuration files. An additional configuration file can be supplied on the command-line to overwrite default parameter values, add/update profiles, configure processes and update environment variables.","title":"Config"},{"location":"usage/config/#parameters","text":"key default description GRCh37.reference.fasta installed human_g1k_v37 GRCh37.reference.fastaFai installed GRCh37.reference.fastaGzi installed GRCh38.reference.fasta installed GCA_000001405.15_GRCh38_no_alt_analysis_set GRCh38.reference.fastaFai installed GRCh38.reference.fastaGzi installed Warning: Please take note of the fact that for a different reference fasta.gz the unzipped referenfasta file is also required. Both the zipped and unzipped fasta should have an index.","title":"Parameters"},{"location":"usage/config/#fastq","text":"key default description GRCh37.reference.fastaMmi installed for details, see here GRCh38.reference.fastaMmi installed for details, see here minimap2.soft_clipping true In SAM output, use soft clipping for supplementary alignments (required when STR calling with Straglr)","title":"FASTQ"},{"location":"usage/config/#cram","text":"key default description cram.call_snv true enable/disable the detection of short variants cram.call_str true enable/disable the detection of short tandem repeats cram.call_sv true enable/disable the detection of structural variants snv.clair3.illumina.model_name ilmn for details, see here snv.clair3.nanopore.model_name r941_prom_sup_g5014 for details, see here snv.clair3.pacbio_hifi.model_name hifi for details, see here str.expansionhunter.aligner dag-aligner for details, see here . allowed values: [dag-aligner, path-aligner] str.expansionhunter.analysis_mode streaming for details, see here . allowed values: [seeking , streaming] str.expansionhunter.log_level warn for details, see here . allowed values: [trace, debug, info, warn, or error] str.expansionhunter.region_extension_length 1000 for details, see here str.expansionhunter.GRCh37.variant_catalog installed for details, see here str.expansionhunter.GRCh38.variant_catalog installed for details, see here str.straglr.min_support 2 minimum number of support reads for an expansion to be captured in genome-scan, see here str.straglr.min_cluster_size 2 minimum number of reads required to constitute a cluster (allele) in GMM clustering, see here str.straglr.GRCh38.loci installed from here","title":"CRAM"},{"location":"usage/config/#vcf","text":"key default description vcf.start allowed values: [normalize, annotate, classify, filter, inheritance, classify_samples, filter_samples]. for reanalysis this defines from which step to start the workflow vcf.annotate.annotsv_cache_dir installed vcf.annotate.ensembl_gene_mapping installed vcf.annotate.vep_buffer_size 1000 for details, see here vcf.annotate.vep_cache_dir installed vcf.annotate.vep_plugin_dir installed vcf.annotate.vep_plugin_hpo installed vcf.annotate.vep_plugin_inheritance installed vcf.annotate.vep_plugin_vkgl_mode 1 allowed values: [0=full VKGL, 1=public VKGL]. update vcf.annotate.GRCh38.vep_plugin_vkgl accordingly vcf.annotate.GRCh37.capice_model installed vcf.annotate.GRCh37.vep_custom_gnomad installed vcf.annotate.GRCh37.vep_custom_clinvar installed vcf.annotate.GRCh37.vep_custom_phylop installed vcf.annotate.GRCh37.vep_plugin_spliceai_indel installed vcf.annotate.GRCh37.vep_plugin_spliceai_snv installed vcf.annotate.GRCh37.vep_plugin_utrannotator installed vcf.annotate.GRCh37.vep_plugin_vkgl installed vcf.annotate.GRCh38.capice_model installed vcf.annotate.GRCh38.vep_custom_gnomad installed vcf.annotate.GRCh38.vep_custom_clinvar installed vcf.annotate.GRCh38.vep_custom_phylop installed vcf.annotate.GRCh38.vep_plugin_spliceai_indel installed vcf.annotate.GRCh38.vep_plugin_spliceai_snv installed vcf.annotate.GRCh38.vep_plugin_utrannotator installed vcf.annotate.GRCh38.vep_plugin_vkgl installed update vcf.annotate.vep_plugin_vkgl_mode accordingly vcf.classify.annotate_labels 0 allowed values: [0=false, 1=true]. annotate variant-consequences with classification tree labels vcf.classify.annotate_path 1 allowed values: [0=false, 1=true]. annotate variant-consequences with classification tree path vcf.classify.GRCh37.decision_tree installed for details, see here vcf.classify.GRCh38.decision_tree installed for details, see here vcf.classify_samples.annotate_labels 0 allowed values: [0=false, 1=true]. annotate variant-consequences per sample with classification tree labels vcf.classify_samples.annotate_path 1 allowed values: [0=false, 1=true]. annotate variant-consequences per sample with classification tree path vcf.classify_samples.GRCh37.decision_tree installed for details, see here vcf.classify_samples.GRCh38.decision_tree installed for details, see here vcf.filter.classes VUS,LP,P for details, see here vcf.filter.consequences true allowed values: [true, false]. true: filter individual consequences, false: keep all consequences for a variant if one consequence filter passes. vcf.filter_samples.classes MV,OK for details, see here vcf.report.gado_genes installed vcf.report.gado_hpo installed vcf.report.gado_predict_info installed vcf.report.gado_predict_matrix installed vcf.report.include_crams true allowed values: [true, false]. true: include cram files in the report for showing alignments in the genome browser, false: do not include the crams in the report, no aligments are shown in the genome browser. This will result in a smaller report size. vcf.report.max_records vcf.report.max_samples vcf.report.template for details, see here vcf.report.GRCh37.genes installed vcf.report.GRCh38.genes installed","title":"VCF"},{"location":"usage/config/#profiles","text":"VIP pre-defines two profiles. The default profile is Slurm with fallback to local in case Slurm cannot be discovered. key description local for details, see here slurm for details, see here Additional profiles (for details, see here ) can be added to your configuration file and used on the command-line, for example to run VIP on the Amazon, Azure or Google Cloud.","title":"Profiles"},{"location":"usage/config/#process","text":"By default, each process gets assigned 4 cpus , 8GB of memory and a max runtime of 4 hours . Depending on your system specifications and your analysis you might need to use updated values. For information on how to update process configuration see the Nextflow documentation . The following sections list all processes and their non-default configuration.","title":"Process"},{"location":"usage/config/#fastq_1","text":"process configuration concat_fastq default concat_fastq_paired_end default minimap2_align cpus=8 memory='16GB' time='23h' minimap2_align_paired_end cpus=8 memory='16GB' time='23h' minimap2_index cpus=8 memory='16GB' time='23h'","title":"FASTQ"},{"location":"usage/config/#cram_1","text":"process configuration samtools_addreplacerg default clair3_call cpus=4 memory='8GB' time='5h' clair3_call_publish default manta_call cpus=4 memory='8GB' time='5h' manta_call_publish default samtools_index default cutesv_call cpus=4 memory='8GB' time='5h'","title":"CRAM"},{"location":"usage/config/#vcf_1","text":"process configuration annotate cpus=4 memory='8GB' time='4h' annotate_publish default classify memory = '2GB' classify_publish default classify_samples memory = '2GB' classify_samples_publish default concat default convert default filter default filter_samples default index memory='100MB' time='30m' inheritance memory = '2GB' merge_gvcf memory='2GB' time='30m' merge_vcf default normalize default report memory = '4GB' slice default split memory='100MB' time='30m' stats default","title":"VCF"},{"location":"usage/config/#environment","text":"See https://github.com/molgenis/vip/tree/main/config for an overview of available environment variables. Notably this allows to use different Apptainer containers for the tools that VIP relies on.","title":"Environment"},{"location":"usage/input/","text":"Input \u00b6 The --input value is a tab-separated file (sample-sheet) with each row describing the data and metadata of a sample. A minimal sample-sheet for the vcf workflow could look like this: individual_id vcf sample0 sample0.vcf.gz sample1 sample1.vcf.gz sample2 sample2.vcf.gz Sample-sheet values are case sensitive. Columns can contain values of different types: type description boolean allowed values: [ true , false ] enum categorical value file absolute file path or file path relative to the sample sheet file list comma-separated list of file paths string text string list comma-separated list of strings The following sections describe the columns that can be used in every sample-sheet followed by workflow specific columns. Columns \u00b6 column type required default description project_id string vip project identifier, see here family_id string fam<index> family identifier individual_id string yes sample identifier of the individual paternal_id string sample identifier of the father maternal_id string sample identifier of the mother sex enum unknown sex values: [male,female] affected boolean unknown affected status whether the individual is affected proband boolean depends 1 individual being reported on hpo_ids string list regex: /HP:\\d{7}/ assembly enum GRCh38 allowed values: [ GRCh37 , GRCh38 ], value must be the same for all project samples sequencing_method enum WGS allowed values: [ WES , WGS ], value must be the same for all project samples 1 Exception: if no probands are defined in the sample-sheet then all samples are considered to be probands. Columns: FASTQ \u00b6 column type required default description fastq file list yes 2 allowed file extensions: [ fastq , fastq.gz , fq , fq.gz ]. single-reads file(s) fastq_r1 file list yes 2 allowed file extensions: [ fastq , fastq.gz , fq , fq.gz ]. paired-end reads file(s) #1 fastq_r2 file list yes 2 allowed file extensions: [ fastq , fastq.gz , fq , fq.gz ]. paired-end reads file(s) #2 sequencing_platform enum illumina allowed values: [ illumina , nanopore , pacbio_hifi ], value must be the same for all project samples 2 Either the fastq or the fastq_r1 and fastq_r2 are required. Columns: CRAM \u00b6 column type required default description cram file yes allowed file extensions: [ bam , cram , sam ] sequencing_platform enum illumina allowed values: [ illumina , nanopore , pacbio_hifi ], value must be the same for all project samples Columns: VCF \u00b6 column type required default description vcf file yes allowed file extensions: [ vcf , vcf.gz , vcf.bgz , bcf , bcf.gz , bcf.bgz ], value must be the same for all project samples cram file allowed file extensions: [ bam , cram , sam ]","title":"Input"},{"location":"usage/input/#input","text":"The --input value is a tab-separated file (sample-sheet) with each row describing the data and metadata of a sample. A minimal sample-sheet for the vcf workflow could look like this: individual_id vcf sample0 sample0.vcf.gz sample1 sample1.vcf.gz sample2 sample2.vcf.gz Sample-sheet values are case sensitive. Columns can contain values of different types: type description boolean allowed values: [ true , false ] enum categorical value file absolute file path or file path relative to the sample sheet file list comma-separated list of file paths string text string list comma-separated list of strings The following sections describe the columns that can be used in every sample-sheet followed by workflow specific columns.","title":"Input"},{"location":"usage/input/#columns","text":"column type required default description project_id string vip project identifier, see here family_id string fam<index> family identifier individual_id string yes sample identifier of the individual paternal_id string sample identifier of the father maternal_id string sample identifier of the mother sex enum unknown sex values: [male,female] affected boolean unknown affected status whether the individual is affected proband boolean depends 1 individual being reported on hpo_ids string list regex: /HP:\\d{7}/ assembly enum GRCh38 allowed values: [ GRCh37 , GRCh38 ], value must be the same for all project samples sequencing_method enum WGS allowed values: [ WES , WGS ], value must be the same for all project samples 1 Exception: if no probands are defined in the sample-sheet then all samples are considered to be probands.","title":"Columns"},{"location":"usage/input/#columns-fastq","text":"column type required default description fastq file list yes 2 allowed file extensions: [ fastq , fastq.gz , fq , fq.gz ]. single-reads file(s) fastq_r1 file list yes 2 allowed file extensions: [ fastq , fastq.gz , fq , fq.gz ]. paired-end reads file(s) #1 fastq_r2 file list yes 2 allowed file extensions: [ fastq , fastq.gz , fq , fq.gz ]. paired-end reads file(s) #2 sequencing_platform enum illumina allowed values: [ illumina , nanopore , pacbio_hifi ], value must be the same for all project samples 2 Either the fastq or the fastq_r1 and fastq_r2 are required.","title":"Columns: FASTQ"},{"location":"usage/input/#columns-cram","text":"column type required default description cram file yes allowed file extensions: [ bam , cram , sam ] sequencing_platform enum illumina allowed values: [ illumina , nanopore , pacbio_hifi ], value must be the same for all project samples","title":"Columns: CRAM"},{"location":"usage/input/#columns-vcf","text":"column type required default description vcf file yes allowed file extensions: [ vcf , vcf.gz , vcf.bgz , bcf , bcf.gz , bcf.bgz ], value must be the same for all project samples cram file allowed file extensions: [ bam , cram , sam ]","title":"Columns: VCF"},{"location":"usage/output/","text":"Output \u00b6 Click here for a live example After VIP completes successfully the path specified by --output contains content similar to: .nextflow .nxf.home .nxf.log .nxf.tmp .nxf.work intermediates nxf_report.html nxf_timeline.html my_project_id.html my_project_id.vcf.gz my_project_id.vcf.gz.csi Report \u00b6 For each project defined in your --input sample-sheet a set of three files is created: my_project.html my_project.vcf.gz my_project.vcf.gz.csi In case no project identifiers were supplied these files will be called: vip.html vip.vcf.gz vip.vcf.gz.csi vip.html is an interactive report based on vip.vcf.gz that can be viewed in any modern browser vip.vcf.gz contains annotated candidate variants for interpretation vip.vcf.gz.csi is the corresponding index file By default, the report is a self-contained .html file that does not depend on external websites. All data and code to interact with and display this data is contained in one file. This ensures that no internet connection is required to view the report and enables easy sharing with other people. Live example #0 Live example #0 Live example #0 Above: report example Intermediates \u00b6 VIP publishes selected intermediate results to allow reanalysis using the vcf.start parameter . Additionaly these results can be used to understand why variant records did not make it into the report. The content of the intermediates directory depends on the used --workflow and looks similar to: hlhs_famA_grch38_annotations.vcf.gz hlhs_famA_grch38_annotations.vcf.gz.csi hlhs_famA_grch38_classifications.vcf.gz hlhs_famA_grch38_classifications.vcf.gz.csi hlhs_famA_grch38_famA_sample0_small_variants.vcf.gz hlhs_famA_grch38_famA_sample0_small_variants.vcf.gz.csi hlhs_famA_grch38_famA_sample0_sv.vcf.gz hlhs_famA_grch38_famA_sample0_sv.vcf.gz.csi hlhs_famA_grch38_famA_sample1_small_variants.vcf.gz hlhs_famA_grch38_famA_sample1_small_variants.vcf.gz.csi hlhs_famA_grch38_famA_sample1_sv.vcf.gz hlhs_famA_grch38_famA_sample1_sv.vcf.gz.csi hlhs_famA_grch38_famA_sample2_small_variants.vcf.gz hlhs_famA_grch38_famA_sample2_small_variants.vcf.gz.csi hlhs_famA_grch38_famA_sample2_sv.vcf.gz hlhs_famA_grch38_famA_sample2_sv.vcf.gz.csi Other \u00b6 Besides the result files and intermediate files the following data is generated: .nextflow .nxf.home .nxf.log .nxf.tmp .nxf.work nxf_report.html nxf_timeline.html For details, see the Nextflow documentation .","title":"Output"},{"location":"usage/output/#output","text":"Click here for a live example After VIP completes successfully the path specified by --output contains content similar to: .nextflow .nxf.home .nxf.log .nxf.tmp .nxf.work intermediates nxf_report.html nxf_timeline.html my_project_id.html my_project_id.vcf.gz my_project_id.vcf.gz.csi","title":"Output"},{"location":"usage/output/#report","text":"For each project defined in your --input sample-sheet a set of three files is created: my_project.html my_project.vcf.gz my_project.vcf.gz.csi In case no project identifiers were supplied these files will be called: vip.html vip.vcf.gz vip.vcf.gz.csi vip.html is an interactive report based on vip.vcf.gz that can be viewed in any modern browser vip.vcf.gz contains annotated candidate variants for interpretation vip.vcf.gz.csi is the corresponding index file By default, the report is a self-contained .html file that does not depend on external websites. All data and code to interact with and display this data is contained in one file. This ensures that no internet connection is required to view the report and enables easy sharing with other people. Live example #0 Live example #0 Live example #0 Above: report example","title":"Report"},{"location":"usage/output/#intermediates","text":"VIP publishes selected intermediate results to allow reanalysis using the vcf.start parameter . Additionaly these results can be used to understand why variant records did not make it into the report. The content of the intermediates directory depends on the used --workflow and looks similar to: hlhs_famA_grch38_annotations.vcf.gz hlhs_famA_grch38_annotations.vcf.gz.csi hlhs_famA_grch38_classifications.vcf.gz hlhs_famA_grch38_classifications.vcf.gz.csi hlhs_famA_grch38_famA_sample0_small_variants.vcf.gz hlhs_famA_grch38_famA_sample0_small_variants.vcf.gz.csi hlhs_famA_grch38_famA_sample0_sv.vcf.gz hlhs_famA_grch38_famA_sample0_sv.vcf.gz.csi hlhs_famA_grch38_famA_sample1_small_variants.vcf.gz hlhs_famA_grch38_famA_sample1_small_variants.vcf.gz.csi hlhs_famA_grch38_famA_sample1_sv.vcf.gz hlhs_famA_grch38_famA_sample1_sv.vcf.gz.csi hlhs_famA_grch38_famA_sample2_small_variants.vcf.gz hlhs_famA_grch38_famA_sample2_small_variants.vcf.gz.csi hlhs_famA_grch38_famA_sample2_sv.vcf.gz hlhs_famA_grch38_famA_sample2_sv.vcf.gz.csi","title":"Intermediates"},{"location":"usage/output/#other","text":"Besides the result files and intermediate files the following data is generated: .nextflow .nxf.home .nxf.log .nxf.tmp .nxf.work nxf_report.html nxf_timeline.html For details, see the Nextflow documentation .","title":"Other"},{"location":"usage/workflow/","text":"Workflow \u00b6 VIP consists of three workflows depending on the type of input data: fastq, bam/cram or (g)vcf. The fastq workflow is an extension of the cram workflow. The cram workflow is an extension of the vcf workflow. The vcf workflow produces the pipeline outputs as described here . The following sections provide an overview of the steps of each of these workflows. flowchart TD p0((Channel.from)) p1([map]) p2([map]) p3([branch]) p4[minimap2_index] p5([map]) p6([mix]) p7([branch]) p8([branch]) p9([map]) p10[fastq:concat_fastq_paired_end] p11([map]) p12([mix]) p13([map]) p14[fastq:minimap2_align_paired_end] p15([map]) p16([branch]) p17([map]) p18[fastq:concat_fastq] p19([map]) p20([mix]) p21([map]) p22[fastq:minimap2_align] p23([map]) p24([mix]) p25([branch]) p26([map]) p27[fastq:cram:samtools_index] p28([map]) p29([mix]) p30([flatMap]) p31([multiMap]) p32([map]) p33[fastq:cram:clair3_call] p34([map]) p35([multiMap]) p36([map]) p37([groupTuple]) p38([map]) p39[fastq:cram:merge_gvcf] p40([map]) p41([map]) p42([groupTuple]) p43([map]) p44[fastq:cram:clair3_call_publish] p45(( )) p46([branch]) p47([map]) p48[fastq:cram:samtools_addreplacerg] p49([map]) p50([groupTuple]) p51([map]) p52[fastq:cram:manta_call] p53([map]) p54([multiMap]) p55([map]) p56([groupTuple]) p57([map]) p58[fastq:cram:manta_call_publish] p59(( )) p60([map]) p61[fastq:cram:sniffles2_call] p62([map]) p63([groupTuple]) p64([map]) p65[fastq:cram:sniffles2_combined_call] p66([map]) p67([multiMap]) p68([map]) p69([groupTuple]) p70([map]) p71[fastq:cram:sniffles_call_publish] p72(( )) p73([mix]) p74([mix]) p75([map]) p76([groupTuple]) p77([map]) p78[fastq:cram:concat_vcf] p79([flatMap]) p80([map]) p81([groupTuple]) p82([map]) p83([branch]) p84([map]) p85[fastq:cram:vcf:convert] p86([map]) p87([map]) p88[fastq:cram:vcf:index] p89([map]) p90([map]) p91[fastq:cram:vcf:stats] p92([map]) p93([mix]) p94([flatMap]) p95([map]) p96([groupTuple]) p97([map]) p98([branch]) p99([map]) p100[fastq:cram:vcf:merge_vcf] p101([map]) p102([map]) p103[fastq:cram:vcf:merge_gvcf] p104([map]) p105([map]) p106([mix]) p107([branch]) p108([flatMap]) p109([branch]) p110([map]) p111[fastq:cram:vcf:split] p112([map]) p113([mix]) p114([map]) p115([branch]) p116([branch]) p117[fastq:cram:vcf:normalize] p118([mix]) p119([branch]) p120[fastq:cram:vcf:annotate] p121([multiMap]) p122([mix]) p123([map]) p124([groupTuple]) p125([map]) p126[fastq:cram:vcf:annotate_publish] p127(( )) p128([mix]) p129([branch]) p130[fastq:cram:vcf:classify] p131([multiMap]) p132([mix]) p133([map]) p134([groupTuple]) p135([map]) p136[fastq:cram:vcf:classify_publish] p137(( )) p138([mix]) p139([branch]) p140[fastq:cram:vcf:filter] p141([branch]) p142([mix]) p143([branch]) p144[fastq:cram:vcf:inheritance] p145([mix]) p146([branch]) p147[fastq:cram:vcf:classify_samples] p148([multiMap]) p149([mix]) p150([map]) p151([groupTuple]) p152([map]) p153[fastq:cram:vcf:classify_samples_publish] p154(( )) p155([mix]) p156([branch]) p157[fastq:cram:vcf:filter_samples] p158([branch]) p159([mix]) p160([map]) p161([groupTuple]) p162([map]) p163([branch]) p164[fastq:cram:vcf:concat] p165([map]) p166([branch]) p167([map]) p168([mix]) p169([branch]) p170([flatMap]) p171([map]) p172[fastq:cram:vcf:slice] p173([map]) p174([map]) p175([groupTuple]) p176([map]) p177([mix]) p178([map]) p179[fastq:cram:vcf:report] p180(( )) p0 --> p1 p1 --> p2 p2 --> p3 p3 --> p6 p3 --> p4 p4 --> p5 p5 -->|ch_index_indexed| p6 p6 -->|meta| p7 p7 --> p16 p7 --> p8 p8 --> p9 p8 --> p12 p9 --> p10 p10 --> p11 p11 -->|ch_input_paired_end_merged| p12 p12 --> p13 p13 --> p14 p14 --> p15 p15 -->|ch_input_paired_end_aligned| p24 p16 --> p20 p16 --> p17 p17 --> p18 p18 --> p19 p19 -->|ch_input_single_merged| p20 p20 --> p21 p21 --> p22 p22 --> p23 p23 -->|ch_input_single_aligned| p24 p24 -->|meta| p25 p25 --> p26 p25 --> p29 p26 --> p27 p27 --> p28 p28 -->|ch_cram_indexed| p29 p29 --> p30 p30 --> p31 p31 --> p32 p31 --> p46 p32 --> p33 p33 --> p34 p34 --> p35 p35 --> p41 p35 --> p36 p36 --> p37 p37 --> p38 p38 --> p39 p39 --> p40 p40 -->|ch_vcf_chunked_snvs_merged| p74 p41 --> p42 p42 --> p43 p43 --> p44 p44 --> p45 p46 --> p60 p46 --> p47 p47 --> p48 p48 --> p49 p49 --> p50 p50 --> p51 p51 --> p52 p52 --> p53 p53 --> p54 p54 --> p73 p54 --> p55 p55 --> p56 p56 --> p57 p57 --> p58 p58 --> p59 p60 --> p61 p61 --> p62 p62 --> p63 p63 --> p64 p64 --> p65 p65 --> p66 p66 --> p67 p67 --> p73 p67 --> p68 p68 --> p69 p69 --> p70 p70 --> p71 p71 --> p72 p73 -->|ch_vcf_chunked_svs_done| p74 p74 --> p75 p75 --> p76 p76 --> p77 p77 --> p78 p78 --> p79 p79 -->|meta| p80 p80 --> p81 p81 --> p82 p82 --> p83 p83 --> p90 p83 --> p93 p83 --> p87 p83 --> p84 p84 --> p85 p85 --> p86 p86 -->|ch_vcfs_converted| p93 p87 --> p88 p88 --> p89 p89 -->|ch_vcfs_indexed| p93 p90 --> p91 p91 --> p92 p92 -->|ch_vcfs_statsed| p93 p93 --> p94 p94 -->|ch_vcfs_preprocessed| p95 p95 --> p96 p96 --> p97 p97 --> p98 p98 --> p99 p98 --> p102 p98 --> p105 p99 --> p100 p100 --> p101 p101 -->|ch_project_vcfs_merged_vcfs| p106 p102 --> p103 p103 --> p104 p104 -->|ch_project_vcfs_merged_gvcfs| p106 p105 --> p106 p106 -->|ch_project_vcfs_merged| p107 p107 --> p113 p107 --> p108 p108 --> p109 p109 --> p113 p109 --> p110 p110 --> p111 p111 --> p112 p112 -->|ch_inputs_splitted| p113 p113 -->|ch_inputs_scattered| p114 p114 --> p115 p115 --> p116 p115 --> p122 p116 --> p117 p116 --> p118 p117 --> p118 p118 --> p119 p119 --> p128 p119 --> p120 p120 --> p121 p121 --> p128 p121 --> p122 p122 --> p123 p123 --> p124 p124 --> p125 p125 --> p126 p126 --> p127 p128 --> p129 p129 --> p138 p129 --> p130 p130 --> p131 p131 --> p138 p131 --> p132 p115 --> p132 p132 --> p133 p133 --> p134 p134 --> p135 p135 --> p136 p136 --> p137 p138 --> p139 p139 --> p140 p139 --> p142 p140 --> p141 p141 --> p142 p141 --> p149 p142 --> p143 p143 --> p145 p143 --> p144 p144 --> p145 p145 --> p146 p146 --> p147 p146 --> p155 p147 --> p148 p148 --> p149 p148 --> p155 p115 --> p149 p149 --> p150 p150 --> p151 p151 --> p152 p152 --> p153 p153 --> p154 p155 --> p156 p156 --> p159 p156 --> p157 p157 --> p158 p158 --> p159 p158 --> p159 p115 --> p159 p141 --> p159 p159 --> p160 p160 --> p161 p161 --> p162 p162 --> p163 p163 --> p164 p163 --> p167 p164 --> p165 p165 --> p166 p166 --> p168 p166 --> p168 p167 -->|ch_output_singleton| p168 p168 --> p169 p169 --> p170 p169 --> p177 p170 --> p171 p171 --> p172 p172 --> p173 p173 --> p174 p174 --> p175 p175 --> p176 p176 -->|ch_sliced| p177 p177 --> p178 p178 --> p179 p179 --> p180 Above: Nextflow rendering of the fastq workflow FASTQ \u00b6 The fastq workflow consists of the following steps: Parallelize sample sheet per sample and for each sample Discover fastq index files and create missing indices In case of multiple fastq files per sample, concatenate the files Alignment using minimap2 producing a cram file per sample Continue with step 2. of the cram workflow For details, see here . CRAM \u00b6 The cram workflow consists of the following steps: Parallelize sample sheet per sample and for each sample Discover cram index files and create missing indices Discover short tandem repeats and publish as intermediate result. Using ExpansionHunter for Illumina short read data. Using this fork of Straglr for PacBio and Nanopore long read data, this fork is chosen over the original Straglr because of the VCF output that enables VIP to combine it with the SV and SNV data in the VCF workflow. Parallelize cram in chunks consisting of one or more contigs and for each chunk Perform short variant calling with Clair3 producing a gvcf file per chunk per sample, the gvcfs of the samples in a project are than merged to one vcf per project (using GLnexus . Perform structural variant calling with Manta or cuteSV producing a vcf file per chunk per project. Concatenate short variant calling and structural variant calling vcf files per chunk per sample Continue with step 3. of the vcf workflow Known limitation: Clair3 is not calling the small variants on the Mitochondia. For details, see here . VCF \u00b6 The vcf workflow consists of the following steps: Parallelize sample sheet per sample and for each sample Discover cram index files and create missing indices Merge vcf files (using GLnexus in case of .g.vcf files) resulting in one vcf (per chunk) per project If the data is not chunked: parallelize vcf files in chunks consisting of one or more contigs and for each chunk and for each chunk Normalize Annotate Classify Filter Perform inheritance matching Classify in the context of samples Filter in the context of samples Concatenate chunks resulting in one vcf file per project If cram data is available slice the cram files to only keep relevant reads Create report For details, see here .","title":"Workflow"},{"location":"usage/workflow/#workflow","text":"VIP consists of three workflows depending on the type of input data: fastq, bam/cram or (g)vcf. The fastq workflow is an extension of the cram workflow. The cram workflow is an extension of the vcf workflow. The vcf workflow produces the pipeline outputs as described here . The following sections provide an overview of the steps of each of these workflows. flowchart TD p0((Channel.from)) p1([map]) p2([map]) p3([branch]) p4[minimap2_index] p5([map]) p6([mix]) p7([branch]) p8([branch]) p9([map]) p10[fastq:concat_fastq_paired_end] p11([map]) p12([mix]) p13([map]) p14[fastq:minimap2_align_paired_end] p15([map]) p16([branch]) p17([map]) p18[fastq:concat_fastq] p19([map]) p20([mix]) p21([map]) p22[fastq:minimap2_align] p23([map]) p24([mix]) p25([branch]) p26([map]) p27[fastq:cram:samtools_index] p28([map]) p29([mix]) p30([flatMap]) p31([multiMap]) p32([map]) p33[fastq:cram:clair3_call] p34([map]) p35([multiMap]) p36([map]) p37([groupTuple]) p38([map]) p39[fastq:cram:merge_gvcf] p40([map]) p41([map]) p42([groupTuple]) p43([map]) p44[fastq:cram:clair3_call_publish] p45(( )) p46([branch]) p47([map]) p48[fastq:cram:samtools_addreplacerg] p49([map]) p50([groupTuple]) p51([map]) p52[fastq:cram:manta_call] p53([map]) p54([multiMap]) p55([map]) p56([groupTuple]) p57([map]) p58[fastq:cram:manta_call_publish] p59(( )) p60([map]) p61[fastq:cram:sniffles2_call] p62([map]) p63([groupTuple]) p64([map]) p65[fastq:cram:sniffles2_combined_call] p66([map]) p67([multiMap]) p68([map]) p69([groupTuple]) p70([map]) p71[fastq:cram:sniffles_call_publish] p72(( )) p73([mix]) p74([mix]) p75([map]) p76([groupTuple]) p77([map]) p78[fastq:cram:concat_vcf] p79([flatMap]) p80([map]) p81([groupTuple]) p82([map]) p83([branch]) p84([map]) p85[fastq:cram:vcf:convert] p86([map]) p87([map]) p88[fastq:cram:vcf:index] p89([map]) p90([map]) p91[fastq:cram:vcf:stats] p92([map]) p93([mix]) p94([flatMap]) p95([map]) p96([groupTuple]) p97([map]) p98([branch]) p99([map]) p100[fastq:cram:vcf:merge_vcf] p101([map]) p102([map]) p103[fastq:cram:vcf:merge_gvcf] p104([map]) p105([map]) p106([mix]) p107([branch]) p108([flatMap]) p109([branch]) p110([map]) p111[fastq:cram:vcf:split] p112([map]) p113([mix]) p114([map]) p115([branch]) p116([branch]) p117[fastq:cram:vcf:normalize] p118([mix]) p119([branch]) p120[fastq:cram:vcf:annotate] p121([multiMap]) p122([mix]) p123([map]) p124([groupTuple]) p125([map]) p126[fastq:cram:vcf:annotate_publish] p127(( )) p128([mix]) p129([branch]) p130[fastq:cram:vcf:classify] p131([multiMap]) p132([mix]) p133([map]) p134([groupTuple]) p135([map]) p136[fastq:cram:vcf:classify_publish] p137(( )) p138([mix]) p139([branch]) p140[fastq:cram:vcf:filter] p141([branch]) p142([mix]) p143([branch]) p144[fastq:cram:vcf:inheritance] p145([mix]) p146([branch]) p147[fastq:cram:vcf:classify_samples] p148([multiMap]) p149([mix]) p150([map]) p151([groupTuple]) p152([map]) p153[fastq:cram:vcf:classify_samples_publish] p154(( )) p155([mix]) p156([branch]) p157[fastq:cram:vcf:filter_samples] p158([branch]) p159([mix]) p160([map]) p161([groupTuple]) p162([map]) p163([branch]) p164[fastq:cram:vcf:concat] p165([map]) p166([branch]) p167([map]) p168([mix]) p169([branch]) p170([flatMap]) p171([map]) p172[fastq:cram:vcf:slice] p173([map]) p174([map]) p175([groupTuple]) p176([map]) p177([mix]) p178([map]) p179[fastq:cram:vcf:report] p180(( )) p0 --> p1 p1 --> p2 p2 --> p3 p3 --> p6 p3 --> p4 p4 --> p5 p5 -->|ch_index_indexed| p6 p6 -->|meta| p7 p7 --> p16 p7 --> p8 p8 --> p9 p8 --> p12 p9 --> p10 p10 --> p11 p11 -->|ch_input_paired_end_merged| p12 p12 --> p13 p13 --> p14 p14 --> p15 p15 -->|ch_input_paired_end_aligned| p24 p16 --> p20 p16 --> p17 p17 --> p18 p18 --> p19 p19 -->|ch_input_single_merged| p20 p20 --> p21 p21 --> p22 p22 --> p23 p23 -->|ch_input_single_aligned| p24 p24 -->|meta| p25 p25 --> p26 p25 --> p29 p26 --> p27 p27 --> p28 p28 -->|ch_cram_indexed| p29 p29 --> p30 p30 --> p31 p31 --> p32 p31 --> p46 p32 --> p33 p33 --> p34 p34 --> p35 p35 --> p41 p35 --> p36 p36 --> p37 p37 --> p38 p38 --> p39 p39 --> p40 p40 -->|ch_vcf_chunked_snvs_merged| p74 p41 --> p42 p42 --> p43 p43 --> p44 p44 --> p45 p46 --> p60 p46 --> p47 p47 --> p48 p48 --> p49 p49 --> p50 p50 --> p51 p51 --> p52 p52 --> p53 p53 --> p54 p54 --> p73 p54 --> p55 p55 --> p56 p56 --> p57 p57 --> p58 p58 --> p59 p60 --> p61 p61 --> p62 p62 --> p63 p63 --> p64 p64 --> p65 p65 --> p66 p66 --> p67 p67 --> p73 p67 --> p68 p68 --> p69 p69 --> p70 p70 --> p71 p71 --> p72 p73 -->|ch_vcf_chunked_svs_done| p74 p74 --> p75 p75 --> p76 p76 --> p77 p77 --> p78 p78 --> p79 p79 -->|meta| p80 p80 --> p81 p81 --> p82 p82 --> p83 p83 --> p90 p83 --> p93 p83 --> p87 p83 --> p84 p84 --> p85 p85 --> p86 p86 -->|ch_vcfs_converted| p93 p87 --> p88 p88 --> p89 p89 -->|ch_vcfs_indexed| p93 p90 --> p91 p91 --> p92 p92 -->|ch_vcfs_statsed| p93 p93 --> p94 p94 -->|ch_vcfs_preprocessed| p95 p95 --> p96 p96 --> p97 p97 --> p98 p98 --> p99 p98 --> p102 p98 --> p105 p99 --> p100 p100 --> p101 p101 -->|ch_project_vcfs_merged_vcfs| p106 p102 --> p103 p103 --> p104 p104 -->|ch_project_vcfs_merged_gvcfs| p106 p105 --> p106 p106 -->|ch_project_vcfs_merged| p107 p107 --> p113 p107 --> p108 p108 --> p109 p109 --> p113 p109 --> p110 p110 --> p111 p111 --> p112 p112 -->|ch_inputs_splitted| p113 p113 -->|ch_inputs_scattered| p114 p114 --> p115 p115 --> p116 p115 --> p122 p116 --> p117 p116 --> p118 p117 --> p118 p118 --> p119 p119 --> p128 p119 --> p120 p120 --> p121 p121 --> p128 p121 --> p122 p122 --> p123 p123 --> p124 p124 --> p125 p125 --> p126 p126 --> p127 p128 --> p129 p129 --> p138 p129 --> p130 p130 --> p131 p131 --> p138 p131 --> p132 p115 --> p132 p132 --> p133 p133 --> p134 p134 --> p135 p135 --> p136 p136 --> p137 p138 --> p139 p139 --> p140 p139 --> p142 p140 --> p141 p141 --> p142 p141 --> p149 p142 --> p143 p143 --> p145 p143 --> p144 p144 --> p145 p145 --> p146 p146 --> p147 p146 --> p155 p147 --> p148 p148 --> p149 p148 --> p155 p115 --> p149 p149 --> p150 p150 --> p151 p151 --> p152 p152 --> p153 p153 --> p154 p155 --> p156 p156 --> p159 p156 --> p157 p157 --> p158 p158 --> p159 p158 --> p159 p115 --> p159 p141 --> p159 p159 --> p160 p160 --> p161 p161 --> p162 p162 --> p163 p163 --> p164 p163 --> p167 p164 --> p165 p165 --> p166 p166 --> p168 p166 --> p168 p167 -->|ch_output_singleton| p168 p168 --> p169 p169 --> p170 p169 --> p177 p170 --> p171 p171 --> p172 p172 --> p173 p173 --> p174 p174 --> p175 p175 --> p176 p176 -->|ch_sliced| p177 p177 --> p178 p178 --> p179 p179 --> p180 Above: Nextflow rendering of the fastq workflow","title":"Workflow"},{"location":"usage/workflow/#fastq","text":"The fastq workflow consists of the following steps: Parallelize sample sheet per sample and for each sample Discover fastq index files and create missing indices In case of multiple fastq files per sample, concatenate the files Alignment using minimap2 producing a cram file per sample Continue with step 2. of the cram workflow For details, see here .","title":"FASTQ"},{"location":"usage/workflow/#cram","text":"The cram workflow consists of the following steps: Parallelize sample sheet per sample and for each sample Discover cram index files and create missing indices Discover short tandem repeats and publish as intermediate result. Using ExpansionHunter for Illumina short read data. Using this fork of Straglr for PacBio and Nanopore long read data, this fork is chosen over the original Straglr because of the VCF output that enables VIP to combine it with the SV and SNV data in the VCF workflow. Parallelize cram in chunks consisting of one or more contigs and for each chunk Perform short variant calling with Clair3 producing a gvcf file per chunk per sample, the gvcfs of the samples in a project are than merged to one vcf per project (using GLnexus . Perform structural variant calling with Manta or cuteSV producing a vcf file per chunk per project. Concatenate short variant calling and structural variant calling vcf files per chunk per sample Continue with step 3. of the vcf workflow Known limitation: Clair3 is not calling the small variants on the Mitochondia. For details, see here .","title":"CRAM"},{"location":"usage/workflow/#vcf","text":"The vcf workflow consists of the following steps: Parallelize sample sheet per sample and for each sample Discover cram index files and create missing indices Merge vcf files (using GLnexus in case of .g.vcf files) resulting in one vcf (per chunk) per project If the data is not chunked: parallelize vcf files in chunks consisting of one or more contigs and for each chunk and for each chunk Normalize Annotate Classify Filter Perform inheritance matching Classify in the context of samples Filter in the context of samples Concatenate chunks resulting in one vcf file per project If cram data is available slice the cram files to only keep relevant reads Create report For details, see here .","title":"VCF"}]}